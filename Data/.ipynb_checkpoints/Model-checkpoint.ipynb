{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer,HashingVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Word to Vec\n",
    "from gensim.models import Word2Vec\n",
    "data = pd.read_csv('train.csv')\n",
    "data['comments'] = data['comments'].fillna('')\n",
    "comment = [x.lower() for x in data['comments']]\n",
    "for i in range(len(comment)):\n",
    "    comment[i] = comment[i].split()\n",
    "# word_model = Word2Vec(comment, size=100, min_count=1, workers=3)\n",
    "# print word_model['readable']\n",
    "\n",
    "# get the model of prediction \n",
    "kaggle_test = pd.read_csv('test.csv')\n",
    "kaggle_test['comments'] = kaggle_test['comments'].fillna('')\n",
    "kaggle_comment = [x.lower() for x in kaggle_test['comments']]\n",
    "for i in range(len(kaggle_comment)):\n",
    "    kaggle_comment[i] = kaggle_comment[i].split()\n",
    "print len(comment),len(kaggle_comment)\n",
    "comment = np.concatenate((comment, kaggle_comment), axis=0)\n",
    "print len(comment)\n",
    "word_model = Word2Vec(comment, size=100, min_count=1, workers=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Word_data = [[] for x in range(len(comment))]\n",
    "for i in range(len(comment)):\n",
    "    Word_data[i] = [0 for x in range(100)]\n",
    "    for j in range(len(comment[i])):\n",
    "        for k in range(100):\n",
    "            Word_data[i][k] += word_model[comment[i][j]][k]\n",
    "    if (len(comment[i]) > 0):\n",
    "        Word_data[i] = [x / len(comment[i]) for x in Word_data[i]]    \n",
    "print Word_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Train dataset\n",
    "data = np.loadtxt('train.in')\n",
    "# helpfulness |3| 4| 5| 6| 7| 8| 9| 10| 11| 12-31| 32| 33| 34\n",
    "Data_X = data[:, 3:33]\n",
    "Data_Y = data[:, 36]\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(Data_X, Data_Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_model = RandomForestRegressor(n_estimators = 300)\n",
    "first_model.fit(train_X, train_y)\n",
    "y_first_model = first_model.predict(test_X)\n",
    "mse = mean_squared_error(test_y, y_first_model)\n",
    "print(\"MSE : {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Test dataset\n",
    "data = np.loadtxt('test.in')\n",
    "# helpfulness | 7| 8| 9| 10| 11| 12-31| 32| 33| 34\n",
    "test = data[:, 3:33]\n",
    "y_predict = first_model.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Word_data, Data_Y)\n",
    "# Make a pipeline to do unigrams then run linear regression\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "pipeline = Pipeline([\n",
    "        ('regression', RandomForestRegressor(max_depth=50,n_jobs=-1))\n",
    "])\n",
    "cv = GridSearchCV(\n",
    "    pipeline, {}\n",
    ").fit(X_train, y_train)\n",
    "mse = mean_squared_error(y_test, cv.predict(X_test))\n",
    "print(\"MSE: {}\".format(mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# generate test data\n",
    "Word_data = [[] for x in range(len(kaggle_comment))]\n",
    "for i in range(len(kaggle_comment)):\n",
    "    Word_data[i] = [0 for x in range(100)]\n",
    "    for j in range(len(kaggle_comment[i])):\n",
    "        for k in range(100):\n",
    "            Word_data[i][k] += word_model[kaggle_comment[i][j]][k]\n",
    "    if (len(kaggle_comment[i]) > 0):\n",
    "        Word_data[i] = [x / len(kaggle_comment[i]) for x in Word_data[i]]  \n",
    "\n",
    "predictions = cv.predict(Word_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_quality = [0 for i in range(len(predictions))]\n",
    "outfile = open('predict.out','wb')\n",
    "for i in range(len(predictions)):\n",
    "    y_quality[i] = y_predict[i] * 0.2 + 0.8 * predictions[i]\n",
    "    outfile.write(str(y_quality[i]) + '\\n')\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv('submission1.csv')\n",
    "submit['quality'] = y_quality\n",
    "submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model for later\n",
    "import pickle\n",
    "with open('modelCV.pkl', 'wb') as f:\n",
    "    pickle.dump(cv, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
