{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model variation is CNN-rand\n",
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import data_helpers\n",
    "from w2v import train_word2vec\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Input, Merge, Convolution1D, MaxPooling1D\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "# Parameters\n",
    "# ==================================================\n",
    "#\n",
    "# Model Variations. See Kim Yoon's Convolutional Neural Networks for\n",
    "# Sentence Classification, Section 3 for detail.\n",
    "\n",
    "\n",
    "model_variation = 'CNN-rand'  # CNN-rand | CNN-non-static | CNN-static\n",
    "print('Model variation is %s' % model_variation)\n",
    "\n",
    "# Model Hyperparameters\n",
    "sequence_length = 125\n",
    "embedding_dim = 20\n",
    "filter_sizes = (3, 4)\n",
    "num_filters = 150\n",
    "dropout_prob = (0.25, 0.5)\n",
    "hidden_dims = 150\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "val_split = 0.2\n",
    "\n",
    "# Word2Vec parameters, see train_word2vec\n",
    "min_word_count = 1  # Minimum word count\n",
    "context = 10        # Context window size\n",
    "\n",
    "# Data Preparatopn\n",
    "# ==================================================\n",
    "#\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "x, y, vocabulary, vocabulary_inv = data_helpers.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117811, 125) [[0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 1 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 53530\n",
      "(117811, 125) [  212  1714  1001    71  6677  3798    13    49   269    90     3  2025\n",
      "    32    15   201 18300   100    16  2544   211   141    24    16  2725\n",
      "   755  1232   244    10    43    19     7    60    31     1   119   168\n",
      "     7    74    23     4 11661   244    10    94   488   322   166     2\n",
      "   285   120   166     9   979   148    10  1592    12   624     2    17\n",
      "   833  3361   240     9  1184     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0]\n",
      "(117811,) 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if model_variation == 'CNN-non-static' or model_variation == 'CNN-static':\n",
    "    embedding_weights = train_word2vec(\n",
    "        x, vocabulary_inv, embedding_dim, min_word_count, context)\n",
    "    if model_variation == 'CNN-static':\n",
    "        x = embedding_weights[0][x]\n",
    "elif model_variation == 'CNN-rand':\n",
    "    embedding_weights = None\n",
    "else:\n",
    "    raise ValueError('Unknown model variation')\n",
    "\n",
    "# Shuffle data\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices].argmax(axis=1)\n",
    "\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocabulary)))\n",
    "\n",
    "# Building model\n",
    "# ==================================================\n",
    "#\n",
    "# graph subnet with one input and one output,\n",
    "# convolutional layers concateneted in parallel\n",
    "graph_in = Input(shape=(sequence_length, embedding_dim))\n",
    "convs = []\n",
    "for fsz in filter_sizes:\n",
    "    conv = Convolution1D(nb_filter=num_filters,\n",
    "                         filter_length=fsz,\n",
    "                         border_mode='valid',\n",
    "                         activation='relu',\n",
    "                         subsample_length=1)(graph_in)\n",
    "    pool = MaxPooling1D(pool_length=2)(conv)\n",
    "    flatten = Flatten()(pool)\n",
    "    convs.append(flatten)\n",
    "\n",
    "if len(filter_sizes) > 1:\n",
    "    out = Merge(mode='concat')(convs)\n",
    "else:\n",
    "    out = convs[0]\n",
    "\n",
    "graph = Model(input=graph_in, output=out)\n",
    "\n",
    "# main sequential model\n",
    "model = Sequential()\n",
    "if not model_variation == 'CNN-static':\n",
    "    model.add(Embedding(len(vocabulary), embedding_dim, input_length=sequence_length,\n",
    "                        weights=embedding_weights))\n",
    "model.add(Dropout(dropout_prob[0], input_shape=(\n",
    "    sequence_length, embedding_dim)))\n",
    "model.add(graph)\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(dropout_prob[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "print x_shuffled.shape, x_shuffled[1]\n",
    "print y_shuffled.shape, y_shuffled[1]\n",
    "# Training model\n",
    "# ==================================================\n",
    "model.fit(x_shuffled, y_shuffled, batch_size=batch_size,\n",
    "          nb_epoch=num_epochs, validation_split=val_split, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, y, vocabulary, vocabulary_inv = data_helpers.load_pre_data()\n",
    "print x.shape, y.shape\n",
    "if model_variation == 'CNN-non-static' or model_variation == 'CNN-static':\n",
    "    embedding_weights = train_word2vec(\n",
    "        x, vocabulary_inv, embedding_dim, min_word_count, context)\n",
    "    if model_variation == 'CNN-static':\n",
    "        x = embedding_weights[0][x]\n",
    "elif model_variation == 'CNN-rand':\n",
    "    embedding_weights = None\n",
    "else:\n",
    "    raise ValueError('Unknown model variation')\n",
    "\n",
    "# Shuffle data\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices].argmax(axis=1)\n",
    "\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocabulary)))\n",
    "print x[1]\n",
    "print x_shuffled.shape, x_shuffled[1]\n",
    "print y_shuffled.shape, y_shuffled[1]\n",
    "# predict = model.predict_classes(x, batch_size=batch_size,verbose=1)\n",
    "print predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
