{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer,HashingVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Train dataset\n",
    "data = np.loadtxt('train.in')\n",
    "# helpfulness |3| 4| 5| 6| 7| 8| 9| 10| 11| 12-31| 32| 33| 34\n",
    "Data_X = data[:, 3:33]\n",
    "Data_Y = data[:, 36]\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(Data_X, Data_Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_model = RandomForestRegressor(n_estimators = 300)\n",
    "first_model.fit(train_X, train_y)\n",
    "y_first_model = first_model.predict(test_X)\n",
    "mse = mean_squared_error(test_y, y_first_model)\n",
    "print(\"MSE : {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Test dataset\n",
    "data = np.loadtxt('test.in')\n",
    "# helpfulness | 7| 8| 9| 10| 11| 12-31| 32| 33| 34\n",
    "test = data[:, 3:33]\n",
    "y_predict = first_model.predict(test)\n",
    "\n",
    "# clarity | 3| 4| 5| 6| 9| 10| 11| 12-31|32 |33| 35\n",
    "clar_test1 = data[:, 3:7]\n",
    "clar_test2 = data[:, 9:33]\n",
    "clar_test = np.concatenate((clar_test1, clar_test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the data with pandas http://pandas.pydata.org\n",
    "data = pd.read_csv('train.csv')\n",
    "data['comments'] = data['comments'].fillna('')\n",
    "train, test = train_test_split(data)\n",
    "# Make a pipeline to do unigrams then run linear regression\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "pipeline = Pipeline([\n",
    "        ('cv', HashingVectorizer(ngram_range=(1,1))),\n",
    "        ('regression', RandomForestRegressor(max_depth=50,n_jobs=-1))\n",
    "])\n",
    "cv = GridSearchCV(\n",
    "    pipeline, {}\n",
    ").fit(train['comments'], train['quality'])\n",
    "mse = mean_squared_error(test['quality'], cv.predict(test['comments']))\n",
    "print(\"MSE: {}\".format(mse))\n",
    "kaggle_test = pd.read_csv('test.csv')\n",
    "kaggle_test['comments'] = kaggle_test['comments'].fillna('')\n",
    "predictions = cv.predict(kaggle_test['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_quality = [0 for i in range(len(predictions))]\n",
    "outfile = open('predict.out','wb')\n",
    "for i in range(len(predictions)):\n",
    "    y_quality[i] = y_predict[i] * 0.2 + 0.8 * predictions[i]\n",
    "    outfile.write(str(y_quality[i]) + '\\n')\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv('submission1.csv')\n",
    "submit['quality'] = y_quality\n",
    "submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model for later\n",
    "import pickle\n",
    "with open('modelCV.pkl', 'wb') as f:\n",
    "    pickle.dump(cv, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
